{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dg29xAhdPqRJ",
    "outputId": "f59a701a-3d2e-4ce1-efca-ffe7985350d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import input\n",
    "\n",
    "#import system things\n",
    "from tensorflow.examples.tutorials.mnist import input_data # for data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZoYoHnhXx2zt"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Siamese:\n",
    "\n",
    "    # Create model\n",
    "    def __init__(self):\n",
    "        self.x1 = tf.placeholder(tf.float32, [None, 784])\n",
    "        self.x2 = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "        with tf.variable_scope(\"Siamese\") as scope:\n",
    "            self.o1 = self.network(self.x1)\n",
    "            scope.reuse_variables()\n",
    "            self.o2 = self.network(self.x2)\n",
    "\n",
    "        # Create loss\n",
    "        self.y_ = tf.placeholder(tf.float32, [None])\n",
    "        self.loss = self.loss_with_spring()\n",
    "\n",
    "    def network(self, x):\n",
    "        \n",
    "        x = tf.reshape(x,shape=[-1,28,28,1])\n",
    "        activated_conv1 = self.conv_layer('conv_1',x,6)\n",
    "        maxpool1 = self.maxpool_layer('maxp_1',activated_conv1)\n",
    "        \n",
    "        flattened_conv = tf.layers.flatten(maxpool1)\n",
    "        activated_fc1 = self.fc_layer( \"fc1\",flattened_conv, 1024)\n",
    "        activated_fc2 = self.fc_layer(\"fc2\",activated_fc1, 1024)\n",
    "        activated_fc3 = self.fc_layer(\"fc3\",activated_fc2, 2)\n",
    "        \n",
    "        return activated_fc3\n",
    "        \n",
    "    def conv_layer(self,name,inputs,cur_channel):\n",
    "        prev_channel = inputs.get_shape()[3]\n",
    "        init = tf.variance_scaling_initializer(scale=2.0)\n",
    "        w = tf.get_variable(name+\"_w\",dtype=tf.float32,shape=[5,5,prev_channel,cur_channel],initializer=init)\n",
    "        b = tf.get_variable(name+\"_b\",dtype=tf.float32,shape=[cur_channel],initializer = init)\n",
    "        conv = tf.nn.conv2d(inputs,w,strides=[1,1,1,1],padding = \"SAME\")\n",
    "        activation = tf.nn.relu(conv+b)\n",
    "        return activation  \n",
    "      \n",
    "    def maxpool_layer(self,name,inputs):\n",
    "        return tf.nn.max_pool(inputs,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")  \n",
    "    \n",
    "    def fc_layer(self,name,inputs,cur_layer):\n",
    "        prev_layer = inputs.get_shape()[-1]\n",
    "        init = tf.truncated_normal_initializer(stddev=0.01)\n",
    "        w = tf.get_variable(name+\"_w\",dtype=tf.float32,shape=[prev_layer,cur_layer],initializer=init)\n",
    "        b = tf.get_variable(name+\"_b\",dtype=tf.float32,shape=[cur_layer],initializer=init)\n",
    "        activation = tf.nn.relu(tf.matmul(inputs,w)+b)\n",
    "        return activation\n",
    "\n",
    "\n",
    "    def loss_with_spring(self):\n",
    "        margin = 5.0\n",
    "        labels_t = self.y_\n",
    "        labels_f = tf.subtract(1.0, self.y_, name=\"1-yi\")          # labels_ = !labels;\n",
    "        eucd2 = tf.pow(tf.subtract(self.o1, self.o2), 2)\n",
    "        eucd2 = tf.reduce_sum(eucd2, 1)\n",
    "        eucd = tf.sqrt(eucd2+1e-6, name=\"eucd\")\n",
    "        C = tf.constant(margin, name=\"C\")\n",
    "        # yi*||CNN(p1i)-CNN(p2i)||^2 + (1-yi)*max(0, C-||CNN(p1i)-CNN(p2i)||^2)\n",
    "        pos = tf.multiply(labels_t, eucd2, name=\"yi_x_eucd2\")\n",
    "        # neg = tf.multiply(labels_f, tf.subtract(0.0,eucd2), name=\"yi_x_eucd2\")\n",
    "        # neg = tf.multiply(labels_f, tf.maximum(0.0, tf.subtract(C,eucd2)), name=\"Nyi_x_C-eucd_xx_2\")\n",
    "        neg = tf.multiply(labels_f, tf.pow(tf.maximum(tf.subtract(C, eucd), 0), 2), name=\"Nyi_x_C-eucd_xx_2\")\n",
    "        losses = tf.add(pos, neg, name=\"losses\")\n",
    "        loss = tf.reduce_mean(losses, name=\"loss\")\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1055
    },
    "colab_type": "code",
    "id": "0e09o46s2dKc",
    "outputId": "094c7f77-154a-4b99-887a-537024e254e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-46b8d7fc4c22>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-3-b519b765edb3>:24: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0: loss 23.009\n",
      "step 10: loss 20.601\n",
      "step 20: loss 6.981\n",
      "step 30: loss 4.319\n",
      "step 40: loss 4.601\n",
      "step 50: loss 4.517\n",
      "step 60: loss 5.597\n",
      "step 70: loss 6.688\n",
      "step 80: loss 5.095\n",
      "step 90: loss 4.695\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-46b8d7fc4c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mvisualize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visualize' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# prepare data and tf.session\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=False)\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "# setup siamese network\n",
    "siamese = Siamese();\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(siamese.loss)\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "\n",
    "for step in range(100):\n",
    "    batch_x1, batch_y1 = mnist.train.next_batch(128)\n",
    "    batch_x2, batch_y2 = mnist.train.next_batch(128)\n",
    "    batch_y = (batch_y1 == batch_y2).astype('float')\n",
    "    \n",
    "    _, loss_v = sess.run([train_step,siamese.loss], feed_dict={\n",
    "                        siamese.x1: batch_x1,\n",
    "                        siamese.x2: batch_x2,\n",
    "                        siamese.y_: batch_y})\n",
    "\n",
    "    if np.isnan(loss_v):\n",
    "        print('Model diverged with loss = NaN')\n",
    "        quit()\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print ('step %d: loss %.3f' % (step, loss_v))\n",
    "\n",
    "    if step % 1000 == 0 and step > 0:\n",
    "        #saver.save(sess, './model')\n",
    "        embed = siamese.o1.eval({siamese.x1: mnist.test.images})\n",
    "        embed.tofile('embed.txt')\n",
    "\n",
    "# visualize result\n",
    "x_test = mnist.test.images.reshape([-1, 28, 28])\n",
    "y_test = mnist.test.labels\n",
    "#visualize.visualize(embed, x_test, y_test)\n",
    "\n",
    "sess.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Siamese.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
